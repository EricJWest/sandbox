{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5Py Primer\n",
    "---\n",
    "H5Py is a Python library for interacting with HDF5 files. Below are the most commonly used features.\n",
    "\n",
    "Table of Contents:\n",
    "1. [Importing h5py](#section1)\n",
    "2. [Working with files](#section2)\n",
    "3. [Working with groups](#section3)\n",
    "4. [Working with datasets](#section4)\n",
    "5. [Working with attributes](#section5)\n",
    "\n",
    "REFERENCES:\n",
    "- [1] Johansson, *Numerical Python: A Practical Techniques Approach for Industry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing h5py <a id='section1'></a>\n",
    "Before using the various commands from the h5py module, you first have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import h5py\n",
    "import numpy as np #numpy will also be needed for some of the examples below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with files <a id='section2'></a>\n",
    "This section shows examples on how to create new hdf5 files as well as open and read existing hdf5 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new file in write mode\n",
    "%mkdir -p h5py_files\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r+'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the current mode of a file\n",
    "# NOTE: once a file is created/opened, its mode is either read-only ('r') or read-write ('r+'). \n",
    "f.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flush buffer\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close a file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open an existing file in read-only mode (file must exist)\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='r')\n",
    "f.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r+'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open an existing file in read-write mode (file must exist)\n",
    "f.flush()\n",
    "f.close()\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='r+')\n",
    "f.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'h5py_files/testfile2.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-15f54d7e291c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try to create a new file, fail if file already exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h5py_files/testfile2.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'w-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'h5py_files/testfile2.hdf5', errno = 17, error message = 'File exists', flags = 15, o_flags = c2)"
     ]
    }
   ],
   "source": [
    "# try to create a new file, fail if file already exists\n",
    "f2 = h5py.File('h5py_files/testfile2.hdf5', mode='x')\n",
    "f2.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r+'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open an existing file in read-write mode, create file if it doesn't already exist\n",
    "f.flush()\n",
    "f.close()\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='a')\n",
    "f.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with groups <a id='section3'></a>\n",
    "This section illustrates how to create and explore groups in an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make sure the file is opened in read-write mode\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the name of the root group\n",
    "f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/experiment1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new subgroup\n",
    "grp1 = f.create_group(\"experiment1\")\n",
    "grp1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/experiment2/simulation1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a group hierarchy (automatically creating parent groups if they don't already exsist)\n",
    "grp2_s1 = f.create_group(\"experiment2/simulation1\")\n",
    "grp2_s2 = f.create_group(\"experiment2/simulation2\")\n",
    "grp2_s1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<HDF5 group \"/\" (2 members)>,\n",
       " <HDF5 group \"/experiment1\" (0 members)>,\n",
       " <HDF5 group \"/experiment2\" (2 members)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary-like lookup for a group\n",
    "f['/'], f['/experiment1'], f['/experiment2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/experiment2/simulation2\" (0 members)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary-like lookup for a subgroup\n",
    "exp2 = f['/experiment2']\n",
    "exp2['simulation2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experiment1', 'experiment2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of subgroups within a group\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experiment1', <HDF5 group \"/experiment1\" (0 members)>),\n",
       " ('experiment2', <HDF5 group \"/experiment2\" (2 members)>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get (name, value) tuples for each item in a group\n",
    "list(f.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1\n",
      "experiment2\n",
      "experiment2/simulation1\n",
      "experiment2/simulation2\n"
     ]
    }
   ],
   "source": [
    "# traverse the hierarchy of groups in a file\n",
    "f.visit(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1 <HDF5 group \"/experiment1\" (0 members)>\n",
      "experiment2 <HDF5 group \"/experiment2\" (2 members)>\n",
      "experiment2/simulation1 <HDF5 group \"/experiment2/simulation1\" (0 members)>\n",
      "experiment2/simulation2 <HDF5 group \"/experiment2/simulation2\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "# traverse the hierarchy of (name, item) tuples in a file\n",
    "f.visititems(lambda name, item: print(name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# test group membership with the 'in' operator\n",
    "print('simulation1' in f)\n",
    "print('simulation1' in f['experiment1'])\n",
    "print('simulation1' in f['experiment2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/                        Group\r\n",
      "/experiment1             Group\r\n",
      "/experiment2             Group\r\n",
      "/experiment2/simulation1 Group\r\n",
      "/experiment2/simulation2 Group\r\n"
     ]
    }
   ],
   "source": [
    "# use external hdf5 utilities to explore a file (provided by the package hdf5-tools)\n",
    "f.flush()\n",
    "f.close()\n",
    "!h5ls -r ./h5py_files/testfile.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with datasets <a id='section4'></a>\n",
    "This section illustrates how to create, retrieve, modify, and delete datasets in an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make sure the file is opened in read-write mode\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1 <HDF5 group \"/experiment1\" (1 members)>\n",
      "experiment1/simulation1 <HDF5 group \"/experiment1/simulation1\" (1 members)>\n",
      "experiment1/simulation1/data1 <HDF5 dataset \"data1\": shape (100, 100), type \"<f8\">\n",
      "experiment2 <HDF5 group \"/experiment2\" (2 members)>\n",
      "experiment2/simulation1 <HDF5 group \"/experiment2/simulation1\" (0 members)>\n",
      "experiment2/simulation2 <HDF5 group \"/experiment2/simulation2\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset using the 'create_dataset' method\n",
    "data1 = np.random.randn(100, 100)\n",
    "f.create_dataset('experiment1/simulation1/data1', data=data1)\n",
    "f.visititems(lambda name, item: print(name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1 <HDF5 group \"/experiment1\" (1 members)>\n",
      "experiment1/simulation1 <HDF5 group \"/experiment1/simulation1\" (2 members)>\n",
      "experiment1/simulation1/data1 <HDF5 dataset \"data1\": shape (100, 100), type \"<f8\">\n",
      "experiment1/simulation1/data2 <HDF5 dataset \"data2\": shape (100, 100), type \"<f8\">\n",
      "experiment2 <HDF5 group \"/experiment2\" (2 members)>\n",
      "experiment2/simulation1 <HDF5 group \"/experiment2/simulation1\" (0 members)>\n",
      "experiment2/simulation2 <HDF5 group \"/experiment2/simulation2\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset of zeros using 'fillvalue' attribute \n",
    "f.create_dataset('experiment1/simulation1/data2', shape=(100, 100), fillvalue=0, dtype='float64')\n",
    "f.visititems(lambda name, item: print(name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1 <HDF5 group \"/experiment1\" (1 members)>\n",
      "experiment1/simulation1 <HDF5 group \"/experiment1/simulation1\" (3 members)>\n",
      "experiment1/simulation1/data1 <HDF5 dataset \"data1\": shape (100, 100), type \"<f8\">\n",
      "experiment1/simulation1/data2 <HDF5 dataset \"data2\": shape (100, 100), type \"<f8\">\n",
      "experiment1/simulation1/data3 <HDF5 dataset \"data3\": shape (100, 100), type \"<f8\">\n",
      "experiment2 <HDF5 group \"/experiment2\" (2 members)>\n",
      "experiment2/simulation1 <HDF5 group \"/experiment2/simulation1\" (0 members)>\n",
      "experiment2/simulation2 <HDF5 group \"/experiment2/simulation2\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset by direct assignment\n",
    "data3 = np.random.randn(100, 100)\n",
    "f['/experiment1/simulation1/data3'] = data3\n",
    "f.visititems(lambda name, item: print(name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"data1\": shape (100, 100), type \"<f8\">"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive a dataset by dictionary-like lookup\n",
    "dset = f['/experiment1/simulation1/data1']\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name is /experiment1/simulation1/data1\n",
      "dataset type is float64\n",
      "dataset shape is (100, 100)\n",
      "dataset length is 100\n",
      "dataset data are:  [[ 0.00759621 -0.79660501 -0.2410277  ... -1.80652704 -1.30000677\n",
      "  -0.43426946]\n",
      " [ 1.15378264  0.64884298 -0.02068101 ... -0.85425229  0.88495712\n",
      "   0.20576674]\n",
      " [-0.06303498  1.31807936 -0.607546   ... -0.14065196 -0.31403767\n",
      "  -1.60787702]\n",
      " ...\n",
      " [ 0.84856364  0.08263046 -0.55221824 ... -0.05525498 -0.13053546\n",
      "  -1.29125411]\n",
      " [-1.48165655  0.87319025 -1.50751444 ...  0.81342877 -0.37800457\n",
      "  -0.58107189]\n",
      " [-0.72237232 -0.56761963 -1.16381831 ...  0.8182137   1.89720933\n",
      "   0.05937715]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# get dataset attributes\n",
    "print('dataset name is', dset.name)\n",
    "print('dataset type is', dset.dtype)\n",
    "print('dataset shape is', dset.shape)\n",
    "print('dataset length is', dset.len())\n",
    "print('dataset data are: ', dset.value) ### DEPRECATED ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00759621, -0.79660501, -0.2410277 , ..., -1.80652704,\n",
       "        -1.30000677, -0.43426946],\n",
       "       [ 1.15378264,  0.64884298, -0.02068101, ..., -0.85425229,\n",
       "         0.88495712,  0.20576674],\n",
       "       [-0.06303498,  1.31807936, -0.607546  , ..., -0.14065196,\n",
       "        -0.31403767, -1.60787702],\n",
       "       ...,\n",
       "       [ 0.84856364,  0.08263046, -0.55221824, ..., -0.05525498,\n",
       "        -0.13053546, -1.29125411],\n",
       "       [-1.48165655,  0.87319025, -1.50751444, ...,  0.81342877,\n",
       "        -0.37800457, -0.58107189],\n",
       "       [-0.72237232, -0.56761963, -1.16381831, ...,  0.8182137 ,\n",
       "         1.89720933,  0.05937715]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data from a dataset using the 'value' attribute\n",
    "### DEPRECATED ###\n",
    "npdset = dset.value\n",
    "print(type(npdset))\n",
    "npdset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00759621, -0.79660501, -0.2410277 , ..., -1.80652704,\n",
       "        -1.30000677, -0.43426946],\n",
       "       [ 1.15378264,  0.64884298, -0.02068101, ..., -0.85425229,\n",
       "         0.88495712,  0.20576674],\n",
       "       [-0.06303498,  1.31807936, -0.607546  , ..., -0.14065196,\n",
       "        -0.31403767, -1.60787702],\n",
       "       ...,\n",
       "       [ 0.84856364,  0.08263046, -0.55221824, ..., -0.05525498,\n",
       "        -0.13053546, -1.29125411],\n",
       "       [-1.48165655,  0.87319025, -1.50751444, ...,  0.81342877,\n",
       "        -0.37800457, -0.58107189],\n",
       "       [-0.72237232, -0.56761963, -1.16381831, ...,  0.8182137 ,\n",
       "         1.89720933,  0.05937715]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data from dataset using the '[...]' syntax\n",
    "npdset = dset[...]\n",
    "print(type(npdset))\n",
    "npdset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00759621, -0.79660501, -0.2410277 , ..., -1.80652704,\n",
       "        -1.30000677, -0.43426946],\n",
       "       [ 1.15378264,  0.64884298, -0.02068101, ..., -0.85425229,\n",
       "         0.88495712,  0.20576674],\n",
       "       [-0.06303498,  1.31807936, -0.607546  , ..., -0.14065196,\n",
       "        -0.31403767, -1.60787702],\n",
       "       ...,\n",
       "       [ 0.84856364,  0.08263046, -0.55221824, ..., -0.05525498,\n",
       "        -0.13053546, -1.29125411],\n",
       "       [-1.48165655,  0.87319025, -1.50751444, ...,  0.81342877,\n",
       "        -0.37800457, -0.58107189],\n",
       "       [-0.72237232, -0.56761963, -1.16381831, ...,  0.8182137 ,\n",
       "         1.89720933,  0.05937715]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data from dataset using the '[()]' syntax\n",
    "npdset = dset[()]\n",
    "print(type(npdset))\n",
    "npdset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get part of the data from a dataset using numpy-like slicing\n",
    "# NOTE: the slicing is done within the HDF5 library, not NumPy, which means the entire \n",
    "# dataset is not read into memory!!!\n",
    "first_col = dset[:,0]\n",
    "first_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.,\n",
       "       52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63., 64.,\n",
       "       65., 66., 67., 68., 69., 70., 71., 72., 73., 74., 75., 76., 77.,\n",
       "       78., 79., 80., 81., 82., 83., 84., 85., 86., 87., 88., 89., 90.,\n",
       "       91., 92., 93., 94., 95., 96., 97., 98., 99.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change/fill dataset using numpy-like assignments\n",
    "dset[:, 0] = np.arange(100)\n",
    "dset[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment1 <HDF5 group \"/experiment1\" (1 members)>\n",
      "experiment1/simulation1 <HDF5 group \"/experiment1/simulation1\" (2 members)>\n",
      "experiment1/simulation1/data1 <HDF5 dataset \"data1\": shape (100, 100), type \"<f8\">\n",
      "experiment1/simulation1/data2 <HDF5 dataset \"data2\": shape (100, 100), type \"<f8\">\n",
      "experiment2 <HDF5 group \"/experiment2\" (2 members)>\n",
      "experiment2/simulation1 <HDF5 group \"/experiment2/simulation1\" (0 members)>\n",
      "experiment2/simulation2 <HDF5 group \"/experiment2/simulation2\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "# delete items from a group\n",
    "del f['experiment1/simulation1/data3']\n",
    "f.visititems(lambda name, item: print(name, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with attributes <a id='section5'></a>\n",
    "This section illustrates how to read, create, and modify attributes (metadata) conatined in hdf5 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make sure the file is opened in read-write mode\n",
    "f = h5py.File('h5py_files/testfile.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Attributes of HDF5 object at 139836888465832>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access attributes of hdf5 objects using the attrs method\n",
    "f.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive attributes \n",
    "list(f.attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an attribute to the root group\n",
    "f.attrs['description'] = 'Simulation data for project X'\n",
    "list(f['/'].attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mass ratio'], ['mass ratio'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create attributes to a (sub)group\n",
    "f['experiment1'].attrs['mass ratio'] = '2.5'\n",
    "f['experiment2'].attrs['mass ratio'] = '1.0'\n",
    "list(f['experiment1'].attrs.keys()), list(f['experiment2'].attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m1', 'm2', 'r0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create attributes to a dataset\n",
    "f['experiment1/simulation1/data1'].attrs['m1'] = 1.0\n",
    "f['experiment1/simulation1/data1'].attrs['m2'] = 2.5\n",
    "f['experiment1/simulation1/data1'].attrs['r0'] = 30.0\n",
    "list(f['experiment1/simulation1/data1'].attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# test for the existence of an attribute using the 'in' operator\n",
    "print('mass ratio' in f['experiment1'].attrs)\n",
    "print('mass ratio' in f['experiment2'].attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# delete existing attributes\n",
    "del f['experiment1'].attrs['mass ratio']\n",
    "print('mass ratio' in f['experiment1'].attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
